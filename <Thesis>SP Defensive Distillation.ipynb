{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttaran/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/uttaran/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load Structural_Perturbations.py\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "def Exposure(eval_data,e):\n",
    "    e = e/255\n",
    "    for i in range(0,eval_data.shape[0]):\n",
    "        eval_data[i][0:eval_data.shape[1] - 4]+=e\n",
    "    return eval_data\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def Translation(eval_data,l):\n",
    "    temp = np.asarray(eval_data)\n",
    "    temp = np.reshape(temp,(-1,28,28))\n",
    "    M = np.float32([[1,0,l],[0,1,0]])\n",
    "    for i in range(0,eval_data.shape[0]):\n",
    "        temp[i] = cv2.warpAffine(temp[i],M,(28,28))\n",
    "    temp = np.reshape(temp,[eval_data.shape[0],eval_data.shape[1]])\n",
    "    eval_data = temp\n",
    "    return eval_data\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def Rotation(eval_data,angle):\n",
    "    temp = eval_data.reshape(-1,28,28)\n",
    "    s,r,c = temp.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),angle,1)\n",
    "    for i in range (0,s):\n",
    "        temp[i] = cv2.warpAffine(temp[i],M,(c,r))\n",
    "    return temp.reshape(-1,eval_data.shape[1])\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "def Scaling(eval_data,l):\n",
    "    temp = eval_data.reshape(-1,28,28)\n",
    "    s,r,c = temp.shape\n",
    "    for i in range (0,s):\n",
    "        img = cv2.resize(temp[i],None,fx=l, fy=l, interpolation = cv2.INTER_CUBIC)\n",
    "        m = np.int((img.shape[0]-28)/2)\n",
    "        temp[i] = img[m:m+28,m:m+28]\n",
    "    return temp.reshape(-1,eval_data.shape[1])\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def Display(eval_data,t):\n",
    "    l = np.array(eval_data[t])\n",
    "    l = [int (x * 255) for x in l]\n",
    "    l = np.asarray(l)\n",
    "    l = np.reshape(l,(-1,28))\n",
    "    plt.imshow(l,cmap='gray')\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "def Plot(eval_data,eval_labels,mnist_classifier):\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "    pred = mnist_classifier.predict(input_fn=eval_input_fn)\n",
    "    my_array = []\n",
    "    for i, x in enumerate(pred):\n",
    "        temp = x['probabilities']\n",
    "        pos = sorted(temp,reverse=True)\n",
    "        index = [pos.index(v) for v in temp]\n",
    "        my_array.append(index[eval_labels[i]])\n",
    "    count = collections.Counter(my_array)\n",
    "    keys = np.array(list(count.keys()))\n",
    "    values = np.array(list(count.values()))\n",
    "    grid = []\n",
    "    for i in range(0,keys.shape[0]):\n",
    "        grid.append([keys[i],values[i]])\n",
    "    grid = np.array(grid)\n",
    "    grid.view('i8,i8').sort(axis=0)\n",
    "    plt.plot(grid)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "def Test(train_data,train_labels,eval_data,eval_labels,mnist_classifier):\n",
    "    train_eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      shuffle=False)\n",
    "    eval_result1=mnist_classifier.evaluate(input_fn=train_eval_input_fn)\n",
    "    print(\"%%%%%%% Train accuracy %%%%%%%%%%%%\\n\",eval_result1)\n",
    "    [a,b,c] = eval_result1.items()\n",
    "\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "    eval_result2=mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(\"######### Test accuracy #############\\n\",eval_result2)\n",
    "    [d,e,f] = eval_result2.items()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = Exposure(eval_data,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = Translation(eval_data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = Rotation(eval_data,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = Scaling(eval_data,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Display(eval_data,8889)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "  print(\"_THIS_\",type(features))\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits/temprature, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"]),\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy between two logits with temperature applied\n",
    "#returns a 1d array with loss for each row in the inputs\n",
    "def cross_entropy2(tar_soft_t, pred_logits_t):\n",
    "   pred_soft = tf.nn.softmax(pred_logits_t)\n",
    "   pred_log = tf.log(pred_soft)\n",
    "   product = -1 * tar_soft_t * pred_log\n",
    "   return tf.reduce_mean(product)\n",
    "    \n",
    "def custom_loss(y_true, pred_logits, tar_soft_t, pred_logits_t):\n",
    "#    print(tf.losses.sparse_softmax_cross_entropy(labels = y_true, logits = pred_logits))\n",
    "#    print(l * cross_entropy2(tar_soft_t, pred_logits_t))\n",
    "   return loss_weight * tf.losses.sparse_softmax_cross_entropy(labels = y_true, logits = pred_logits) + (1-loss_weight) * cross_entropy2(tar_soft_t, pred_logits_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def student_model_fn(features, labels, mode):\n",
    "\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "  \n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=8,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=8,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 8])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=256, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    pred_logits_t=tf.nn.softmax(logits/temprature, name=\"softmax_tensor\")\n",
    "#     print('a',labels,'b', logits,'c', teacher_soft_t ,'d', pred_logits_t)\n",
    "    loss=custom_loss(labels, logits,teacher_soft_t , pred_logits_t)\n",
    "  else:\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "  \n",
    "    \n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"]),\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temprature=10\n",
    "loss_weight=0.75\n",
    "\n",
    "# mnist_classifier = tf.estimator.Estimator(\n",
    "#   model_fn=cnn_model_fn, model_dir=\"./models/mnist_convnet_model_test1\")\n",
    "\n",
    "# Create the Estimator\n",
    "student_classifier = tf.estimator.Estimator(\n",
    "  model_fn=student_model_fn, model_dir=\"./models/mnist_convnet_student_10_0.75\")\n",
    "\n",
    "# Train the model\n",
    "# train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#   x={\"x\": train_data},\n",
    "#   y=train_labels,\n",
    "#   batch_size=100,\n",
    "#   num_epochs=None,\n",
    "#   shuffle=True)\n",
    "# print(train_data,train_labels,eval_data,eval_labels)\n",
    "\n",
    "# student_classifier.train(\n",
    "#   input_fn=train_input_fn,\n",
    "#   steps=20000,\n",
    "#   hooks=None)\n",
    "# print(\"eva\",type(eval_data))\n",
    "\n",
    "# Evaluate the model and print results\n",
    "# eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#   x={\"x\": eval_data},\n",
    "#   y=eval_labels,\n",
    "#   num_epochs=1,\n",
    "#   shuffle=False)\n",
    "# eval_result=student_classifier.evaluate(input_fn=eval_input_fn)\n",
    "# # output=list(predictions)\n",
    "# print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.9497455, 'loss': 0.17251603, 'global_step': 20001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6765, 'loss': 1.4155765, 'global_step': 20001}\n"
     ]
    }
   ],
   "source": [
    "Test(train_data,train_labels,eval_data,eval_labels,student_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot(eval_data,eval_labels,student_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

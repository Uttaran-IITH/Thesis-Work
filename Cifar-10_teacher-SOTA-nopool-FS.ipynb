{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cifar10\n",
    "from cifar10 import num_classes\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import cv2\n",
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "<_io.BufferedReader name='data/CIFAR-10/cifar-10-batches-py/data_batch_1'>\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "<_io.BufferedReader name='data/CIFAR-10/cifar-10-batches-py/data_batch_2'>\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "<_io.BufferedReader name='data/CIFAR-10/cifar-10-batches-py/data_batch_3'>\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "<_io.BufferedReader name='data/CIFAR-10/cifar-10-batches-py/data_batch_4'>\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "<_io.BufferedReader name='data/CIFAR-10/cifar-10-batches-py/data_batch_5'>\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n",
      "<_io.BufferedReader name='data/CIFAR-10/cifar-10-batches-py/test_batch'>\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,onehot_train=cifar10.load_training_data()\n",
    "test_data,test_labels,onehot_test=cifar10.load_test_data()\n",
    "train_data=train_data.astype('float32')\n",
    "train_labels=train_labels.astype('int32')\n",
    "test_data=test_data.astype('float32')\n",
    "test_labels=test_labels.astype('int32')\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-2\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=weight_decay)\n",
    "filter_size = 3\n",
    "feature_maps = 96\n",
    "acc_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fed0ca435f8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[421])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Squeeze(data,f):\n",
    "    \n",
    "#     #Color depth reduction\n",
    "    temp = np.ndarray.flatten(data)\n",
    "    temp = temp*15\n",
    "    temp = temp.astype(int)\n",
    "    temp = temp/15\n",
    " \n",
    "    #Median Smoothing\n",
    "    temp = temp.reshape(-1,data.shape[1],data.shape[2],data.shape[3])\n",
    "    for i in range (0,temp.shape[0]):\n",
    "        temp[i] = scipy.ndimage.filters.median_filter(temp[i],size=(f,f,f))\n",
    "    \n",
    "    #Non-local Smoothing\n",
    "    r = data.shape[0]\n",
    "    r = int(r)\n",
    "    for i in range (0,r): \n",
    "        y = temp[i].dot(255)\n",
    "        y = y.astype(np.uint8)\n",
    "        temp[i] = cv2.fastNlMeansDenoisingColored(y,None,3,3,7,21)\n",
    "#         if i == 10:\n",
    "#             plt.imshow(temp[i],cmap='gray')\n",
    "    temp = temp.astype(np.float32)/255\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Squeeze(train_data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fed0c0fe400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Squeeze(test_data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_data,axis=(0,1,2,3))\n",
    "std = np.std(train_data,axis=(0,1,2,3))\n",
    "x_train = (train_data-mean)/(std+1e-7)\n",
    "x_test = (test_data-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "      input_layer = tf.reshape(features[\"x\"], [-1, 32, 32,3])\n",
    "      dropout0_1 = tf.contrib.layers.dropout(inputs=input_layer, keep_prob=0.8)  \n",
    "      conv1 = tf.contrib.layers.conv2d(\n",
    "          inputs = dropout0_1,\n",
    "          num_outputs = feature_maps,\n",
    "          kernel_size = filter_size,\n",
    "          weights_regularizer=regularizer,\n",
    "          )\n",
    "      \n",
    "      conv1_bn =  tf.contrib.layers.batch_norm(\n",
    "            inputs=conv1,\n",
    "            fused = True\n",
    "      )\n",
    "      dropout1_2 = tf.contrib.layers.dropout(inputs=conv1_bn, keep_prob=0.7)  \n",
    "      conv2 = tf.contrib.layers.conv2d(\n",
    "          inputs = dropout1_2,\n",
    "          num_outputs = feature_maps,\n",
    "          kernel_size = filter_size,\n",
    "          weights_regularizer=regularizer,\n",
    "          )\n",
    "\n",
    "      conv2_bn =  tf.contrib.layers.batch_norm(\n",
    "            inputs=conv2,\n",
    "            fused = True\n",
    "        )\n",
    "      dropout2_3 = tf.contrib.layers.dropout(inputs=conv2_bn, keep_prob=0.7)\n",
    "\n",
    "      conv3 = tf.contrib.layers.conv2d(\n",
    "          inputs = dropout2_3,\n",
    "          num_outputs = feature_maps,\n",
    "          kernel_size = filter_size,\n",
    "          weights_regularizer=regularizer,\n",
    "          stride = 2\n",
    "          )\n",
    "      conv3_bn =  tf.contrib.layers.batch_norm(\n",
    "            inputs=conv3,\n",
    "            fused = True\n",
    "        )\n",
    "      dropout3_4 = tf.contrib.layers.dropout(inputs=conv3_bn, keep_prob=0.7)  \n",
    "      conv4 = tf.contrib.layers.conv2d(\n",
    "          inputs = dropout3_4,\n",
    "          num_outputs = 2*feature_maps,\n",
    "          kernel_size = filter_size,\n",
    "          weights_regularizer=regularizer,\n",
    "          )\n",
    "\n",
    "      conv4_bn =  tf.contrib.layers.batch_norm(\n",
    "            inputs=conv4,\n",
    "            fused = True\n",
    "        )\n",
    "\n",
    "      \n",
    "      #pool2 = tf.contrib.layers.max_pool2d(inputs = conv4_bn,kernel_size = [2,2],stride = 2)\n",
    "    \n",
    "      \n",
    "        #dropout2 =  tf.contrib.layers.dropout(inputs=pool2, keep_prob=0.7)\n",
    "\n",
    "      dropout4_5 = tf.contrib.layers.dropout(inputs=conv4_bn, keep_prob=0.7)\n",
    "      \n",
    "      conv5 = tf.contrib.layers.conv2d(\n",
    "          inputs = dropout4_5,\n",
    "          num_outputs = 2*feature_maps,\n",
    "          kernel_size = filter_size,\n",
    "          weights_regularizer=regularizer,\n",
    "          )\n",
    "\n",
    "\n",
    "      conv5_bn =  tf.contrib.layers.batch_norm(\n",
    "            inputs=conv5,\n",
    "            fused = True\n",
    "        )\n",
    "      dropout5_6 = tf.contrib.layers.dropout(inputs=conv5_bn, keep_prob=0.7)\n",
    "      \n",
    "      conv6 = tf.contrib.layers.conv2d(\n",
    "          inputs = dropout5_6,\n",
    "          num_outputs = 2*feature_maps,\n",
    "          kernel_size = filter_size,\n",
    "          weights_regularizer=regularizer,\n",
    "          stride = 2\n",
    "          )\n",
    "\n",
    "      conv6_bn =  tf.contrib.layers.batch_norm(\n",
    "            inputs=conv6,\n",
    "            fused = True\n",
    "        )\n",
    "\n",
    "      \n",
    "      #pool3 = tf.contrib.layers.max_pool2d(inputs = conv6_bn,kernel_size = [2,2] ,stride = 2)\n",
    "      dropout3 =  tf.contrib.layers.dropout(inputs=conv6_bn, keep_prob=0.5)\n",
    "      \n",
    "#       print(\"**************************************\")\n",
    "#       print(dropout3.shape)\n",
    "      pool3_flat = tf.reshape(dropout3, [-1, 8* 8* 192])\n",
    "    \n",
    "      logits = tf.layers.dense(inputs=pool3_flat, units=10)\n",
    "      predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.contrib.layers.softmax(logits)\n",
    "  }\n",
    "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "      # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "      loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "      # Configure the Training Op (for TRAIN mode)\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "      # Add evaluation metrics (for EVAL mode)\n",
    "      eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"]),\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_loss(flag):\n",
    "    train_eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      shuffle=False)\n",
    "    eval_result1=cifar_classifier.evaluate(input_fn=train_eval_input_fn)\n",
    "    if flag:\n",
    "        print(\"%%%%%%% Train accuracy %%%%%%%%%%%%\\n\",eval_result1)\n",
    "    [a,b,c] = eval_result1.items()\n",
    "\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": test_data},\n",
    "      y=test_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "    eval_result2=cifar_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    if flag:\n",
    "        print(\"######### Test accuracy #############\\n\",eval_result2)\n",
    "    [d,e,f] = eval_result2.items()\n",
    "    acc_track.append([a[1],d[1]])\n",
    "    return a[1],d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.33268, 'loss': 1.8055656, 'global_step': 1001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.3253, 'loss': 1.8128417, 'global_step': 1001}\n",
      "(0.33268, 0.3253)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.3843, 'loss': 1.6922481, 'global_step': 2001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.3787, 'loss': 1.6936464, 'global_step': 2001}\n",
      "(0.3843, 0.3787)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.40512, 'loss': 1.6349976, 'global_step': 3001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.3986, 'loss': 1.6473105, 'global_step': 3001}\n",
      "(0.40512, 0.3986)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.42396, 'loss': 1.6032412, 'global_step': 4001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4229, 'loss': 1.5994717, 'global_step': 4001}\n",
      "(0.42396, 0.4229)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.41316, 'loss': 1.6442562, 'global_step': 5001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4093, 'loss': 1.6648282, 'global_step': 5001}\n",
      "(0.41316, 0.4093)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.412, 'loss': 1.6842556, 'global_step': 6001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.3991, 'loss': 1.709804, 'global_step': 6001}\n",
      "(0.412, 0.3991)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.44474, 'loss': 1.5974399, 'global_step': 7001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4328, 'loss': 1.6323453, 'global_step': 7001}\n",
      "(0.44474, 0.4328)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.41944, 'loss': 1.6232357, 'global_step': 8001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4114, 'loss': 1.6862292, 'global_step': 8001}\n",
      "(0.41944, 0.4114)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.45198, 'loss': 1.5253482, 'global_step': 9001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4406, 'loss': 1.5488747, 'global_step': 9001}\n",
      "(0.45198, 0.4406)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.48362, 'loss': 1.4296654, 'global_step': 10001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.475, 'loss': 1.4535916, 'global_step': 10001}\n",
      "(0.48362, 0.475)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.50692, 'loss': 1.3802, 'global_step': 11001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4956, 'loss': 1.4317967, 'global_step': 11001}\n",
      "(0.50692, 0.4956)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.4903, 'loss': 1.4217263, 'global_step': 12001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.473, 'loss': 1.4668052, 'global_step': 12001}\n",
      "(0.4903, 0.473)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.5131, 'loss': 1.3667759, 'global_step': 13001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5052, 'loss': 1.4009274, 'global_step': 13001}\n",
      "(0.5131, 0.5052)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.35612, 'loss': 1.9418913, 'global_step': 14001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.3585, 'loss': 1.9385744, 'global_step': 14001}\n",
      "(0.35612, 0.3585)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.45084, 'loss': 1.5359783, 'global_step': 15001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4432, 'loss': 1.5619715, 'global_step': 15001}\n",
      "(0.45084, 0.4432)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.49006, 'loss': 1.440577, 'global_step': 16001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4852, 'loss': 1.4600433, 'global_step': 16001}\n",
      "(0.49006, 0.4852)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.52014, 'loss': 1.349015, 'global_step': 17001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5087, 'loss': 1.3946627, 'global_step': 17001}\n",
      "(0.52014, 0.5087)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.54878, 'loss': 1.294174, 'global_step': 18001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5443, 'loss': 1.3381491, 'global_step': 18001}\n",
      "(0.54878, 0.5443)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.56366, 'loss': 1.2781731, 'global_step': 19001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5424, 'loss': 1.3692456, 'global_step': 19001}\n",
      "(0.56366, 0.5424)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.51876, 'loss': 1.3373291, 'global_step': 20001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5035, 'loss': 1.3734871, 'global_step': 20001}\n",
      "(0.51876, 0.5035)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.59056, 'loss': 1.1778165, 'global_step': 21001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5709, 'loss': 1.2802988, 'global_step': 21001}\n",
      "(0.59056, 0.5709)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.6048, 'loss': 1.1283932, 'global_step': 22001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5871, 'loss': 1.2795556, 'global_step': 22001}\n",
      "(0.6048, 0.5871)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.54828, 'loss': 1.3818196, 'global_step': 23001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5388, 'loss': 1.4587644, 'global_step': 23001}\n",
      "(0.54828, 0.5388)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.56898, 'loss': 1.4310246, 'global_step': 24001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5454, 'loss': 1.4553362, 'global_step': 24001}\n",
      "(0.56898, 0.5454)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.6065, 'loss': 1.16838, 'global_step': 25001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5901, 'loss': 1.2538396, 'global_step': 25001}\n",
      "(0.6065, 0.5901)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.61538, 'loss': 1.0816118, 'global_step': 26001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5867, 'loss': 1.183544, 'global_step': 26001}\n",
      "(0.61538, 0.5867)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.62798, 'loss': 1.0688306, 'global_step': 27001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.603, 'loss': 1.1690966, 'global_step': 27001}\n",
      "(0.62798, 0.603)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.63912, 'loss': 1.03703, 'global_step': 28001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6112, 'loss': 1.1466237, 'global_step': 28001}\n",
      "(0.63912, 0.6112)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.64296, 'loss': 1.0198867, 'global_step': 29001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6146, 'loss': 1.1351062, 'global_step': 29001}\n",
      "(0.64296, 0.6146)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.6049, 'loss': 1.1616101, 'global_step': 30001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5832, 'loss': 1.2384729, 'global_step': 30001}\n",
      "(0.6049, 0.5832)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.64332, 'loss': 1.1212283, 'global_step': 31001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6085, 'loss': 1.3131539, 'global_step': 31001}\n",
      "(0.64332, 0.6085)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.65806, 'loss': 0.9852636, 'global_step': 32001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.617, 'loss': 1.1395683, 'global_step': 32001}\n",
      "(0.65806, 0.617)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.667, 'loss': 0.9808949, 'global_step': 33001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6262, 'loss': 1.1153865, 'global_step': 33001}\n",
      "(0.667, 0.6262)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.6127, 'loss': 1.1450633, 'global_step': 34001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5823, 'loss': 1.2741961, 'global_step': 34001}\n",
      "(0.6127, 0.5823)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.66796, 'loss': 1.0270858, 'global_step': 35001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6284, 'loss': 1.105556, 'global_step': 35001}\n",
      "(0.66796, 0.6284)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.65124, 'loss': 1.007902, 'global_step': 36001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6135, 'loss': 1.1610262, 'global_step': 36001}\n",
      "(0.65124, 0.6135)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.66808, 'loss': 0.94545394, 'global_step': 37001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6245, 'loss': 1.1194663, 'global_step': 37001}\n",
      "(0.66808, 0.6245)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.68576, 'loss': 0.9178862, 'global_step': 38001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6342, 'loss': 1.0983986, 'global_step': 38001}\n",
      "(0.68576, 0.6342)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.6864, 'loss': 0.90575993, 'global_step': 39001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6332, 'loss': 1.107688, 'global_step': 39001}\n",
      "(0.6864, 0.6332)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.68434, 'loss': 0.92001235, 'global_step': 40001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6249, 'loss': 1.1474983, 'global_step': 40001}\n",
      "(0.68434, 0.6249)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.65, 'loss': 0.9919969, 'global_step': 41001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.607, 'loss': 1.1533958, 'global_step': 41001}\n",
      "(0.65, 0.607)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.68378, 'loss': 0.8826334, 'global_step': 42001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6244, 'loss': 1.083695, 'global_step': 42001}\n",
      "(0.68378, 0.6244)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.61212, 'loss': 1.1173519, 'global_step': 43001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5841, 'loss': 1.2532048, 'global_step': 43001}\n",
      "(0.61212, 0.5841)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.67378, 'loss': 0.9683909, 'global_step': 44001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6199, 'loss': 1.2838641, 'global_step': 44001}\n",
      "(0.67378, 0.6199)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.70002, 'loss': 0.8590983, 'global_step': 45001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6415, 'loss': 1.0913868, 'global_step': 45001}\n",
      "(0.70002, 0.6415)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.70502, 'loss': 0.8585496, 'global_step': 46001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6397, 'loss': 1.1678973, 'global_step': 46001}\n",
      "(0.70502, 0.6397)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.65344, 'loss': 0.97443813, 'global_step': 47001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.609, 'loss': 1.1474215, 'global_step': 47001}\n",
      "(0.65344, 0.609)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.69276, 'loss': 0.8730822, 'global_step': 48001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6378, 'loss': 1.1121745, 'global_step': 48001}\n",
      "(0.69276, 0.6378)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.69522, 'loss': 0.8805297, 'global_step': 49001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6288, 'loss': 1.1441112, 'global_step': 49001}\n",
      "(0.69522, 0.6288)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.69716, 'loss': 0.8545059, 'global_step': 50001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.623, 'loss': 1.1316124, 'global_step': 50001}\n",
      "(0.69716, 0.623)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.71624, 'loss': 0.844107, 'global_step': 51001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6399, 'loss': 1.23324, 'global_step': 51001}\n",
      "(0.71624, 0.6399)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.71458, 'loss': 0.81896013, 'global_step': 52001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6447, 'loss': 1.1021667, 'global_step': 52001}\n",
      "(0.71458, 0.6447)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.72474, 'loss': 0.81859547, 'global_step': 53001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6501, 'loss': 1.137637, 'global_step': 53001}\n",
      "(0.72474, 0.6501)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.71542, 'loss': 0.85548764, 'global_step': 54001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6459, 'loss': 1.1646177, 'global_step': 54001}\n",
      "(0.71542, 0.6459)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.68866, 'loss': 0.9213042, 'global_step': 55001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6235, 'loss': 1.188581, 'global_step': 55001}\n",
      "(0.68866, 0.6235)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.72586, 'loss': 0.79548836, 'global_step': 56001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6535, 'loss': 1.27643, 'global_step': 56001}\n",
      "(0.72586, 0.6535)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.70112, 'loss': 0.9251325, 'global_step': 57001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6376, 'loss': 1.1333365, 'global_step': 57001}\n",
      "(0.70112, 0.6376)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.71392, 'loss': 0.80495644, 'global_step': 58001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6453, 'loss': 1.0911536, 'global_step': 58001}\n",
      "(0.71392, 0.6453)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7314, 'loss': 0.77781165, 'global_step': 59001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6553, 'loss': 1.1808202, 'global_step': 59001}\n",
      "(0.7314, 0.6553)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7092, 'loss': 0.8642112, 'global_step': 60001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6361, 'loss': 1.1545753, 'global_step': 60001}\n",
      "(0.7092, 0.6361)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.728, 'loss': 0.7803034, 'global_step': 61001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6487, 'loss': 1.1217133, 'global_step': 61001}\n",
      "(0.728, 0.6487)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7294, 'loss': 0.7615066, 'global_step': 62001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.649, 'loss': 1.2801406, 'global_step': 62001}\n",
      "(0.7294, 0.649)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.73874, 'loss': 0.7509306, 'global_step': 63001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6466, 'loss': 1.0983919, 'global_step': 63001}\n",
      "(0.73874, 0.6466)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.73154, 'loss': 0.8472368, 'global_step': 64001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6499, 'loss': 1.3905934, 'global_step': 64001}\n",
      "(0.73154, 0.6499)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74076, 'loss': 0.7661978, 'global_step': 65001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6514, 'loss': 1.2313286, 'global_step': 65001}\n",
      "(0.74076, 0.6514)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74124, 'loss': 0.76984143, 'global_step': 66001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6528, 'loss': 1.2272384, 'global_step': 66001}\n",
      "(0.74124, 0.6528)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74118, 'loss': 0.8251367, 'global_step': 67001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6514, 'loss': 1.3085135, 'global_step': 67001}\n",
      "(0.74118, 0.6514)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74664, 'loss': 0.72949016, 'global_step': 68001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6533, 'loss': 1.1579603, 'global_step': 68001}\n",
      "(0.74664, 0.6533)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.71426, 'loss': 0.8103256, 'global_step': 69001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6446, 'loss': 1.102413, 'global_step': 69001}\n",
      "(0.71426, 0.6446)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74646, 'loss': 0.72441065, 'global_step': 70001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6519, 'loss': 1.0875678, 'global_step': 70001}\n",
      "(0.74646, 0.6519)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74998, 'loss': 0.73141074, 'global_step': 71001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.659, 'loss': 1.2638322, 'global_step': 71001}\n",
      "(0.74998, 0.659)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.71942, 'loss': 0.8074419, 'global_step': 72001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6331, 'loss': 1.1672903, 'global_step': 72001}\n",
      "(0.71942, 0.6331)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74262, 'loss': 0.80054486, 'global_step': 73001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6543, 'loss': 1.2387934, 'global_step': 73001}\n",
      "(0.74262, 0.6543)\n",
      "Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74856, 'loss': 0.72504514, 'global_step': 74001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6479, 'loss': 1.1571021, 'global_step': 74001}\n",
      "(0.74856, 0.6479)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74316, 'loss': 0.7361979, 'global_step': 75001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6476, 'loss': 1.1773226, 'global_step': 75001}\n",
      "(0.74316, 0.6476)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75726, 'loss': 0.74561524, 'global_step': 76001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6628, 'loss': 1.2785119, 'global_step': 76001}\n",
      "(0.75726, 0.6628)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75816, 'loss': 0.7012173, 'global_step': 77001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6558, 'loss': 1.2446795, 'global_step': 77001}\n",
      "(0.75816, 0.6558)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.72456, 'loss': 0.7845438, 'global_step': 78001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6389, 'loss': 1.1943479, 'global_step': 78001}\n",
      "(0.72456, 0.6389)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7481, 'loss': 0.7412185, 'global_step': 79001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6497, 'loss': 1.1455051, 'global_step': 79001}\n",
      "(0.7481, 0.6497)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75972, 'loss': 0.7156284, 'global_step': 80001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6577, 'loss': 1.2256643, 'global_step': 80001}\n",
      "(0.75972, 0.6577)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7608, 'loss': 0.69836754, 'global_step': 81001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.66, 'loss': 1.2598948, 'global_step': 81001}\n",
      "(0.7608, 0.66)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7219, 'loss': 0.8028584, 'global_step': 82001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6351, 'loss': 1.2182249, 'global_step': 82001}\n",
      "(0.7219, 0.6351)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75948, 'loss': 0.7057776, 'global_step': 83001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6504, 'loss': 1.1542784, 'global_step': 83001}\n",
      "(0.75948, 0.6504)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76014, 'loss': 0.70670587, 'global_step': 84001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6536, 'loss': 1.2602494, 'global_step': 84001}\n",
      "(0.76014, 0.6536)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75062, 'loss': 0.7337543, 'global_step': 85001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6461, 'loss': 1.2440944, 'global_step': 85001}\n",
      "(0.75062, 0.6461)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7546, 'loss': 0.7498523, 'global_step': 86001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6526, 'loss': 1.281887, 'global_step': 86001}\n",
      "(0.7546, 0.6526)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.64748, 'loss': 1.0828811, 'global_step': 87001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5811, 'loss': 1.3765668, 'global_step': 87001}\n",
      "(0.64748, 0.5811)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74884, 'loss': 0.7249483, 'global_step': 88001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6568, 'loss': 1.2009987, 'global_step': 88001}\n",
      "(0.74884, 0.6568)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74202, 'loss': 0.7439772, 'global_step': 89001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6398, 'loss': 1.1898264, 'global_step': 89001}\n",
      "(0.74202, 0.6398)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76858, 'loss': 0.6747508, 'global_step': 90001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.655, 'loss': 1.1679875, 'global_step': 90001}\n",
      "(0.76858, 0.655)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77072, 'loss': 0.69174224, 'global_step': 91001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6611, 'loss': 1.2898633, 'global_step': 91001}\n",
      "(0.77072, 0.6611)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76484, 'loss': 0.72197926, 'global_step': 92001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.656, 'loss': 1.2092227, 'global_step': 92001}\n",
      "(0.76484, 0.656)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7661, 'loss': 0.6828278, 'global_step': 93001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6505, 'loss': 1.1776052, 'global_step': 93001}\n",
      "(0.7661, 0.6505)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76998, 'loss': 0.7396603, 'global_step': 94001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6596, 'loss': 1.2055223, 'global_step': 94001}\n",
      "(0.76998, 0.6596)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76024, 'loss': 0.69806623, 'global_step': 95001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6496, 'loss': 1.1722091, 'global_step': 95001}\n",
      "(0.76024, 0.6496)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7572, 'loss': 0.70658284, 'global_step': 96001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6505, 'loss': 1.4311082, 'global_step': 96001}\n",
      "(0.7572, 0.6505)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.64488, 'loss': 1.0026753, 'global_step': 97001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6008, 'loss': 1.1648735, 'global_step': 97001}\n",
      "(0.64488, 0.6008)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.73434, 'loss': 0.7981595, 'global_step': 98001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6525, 'loss': 1.1811149, 'global_step': 98001}\n",
      "(0.73434, 0.6525)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.73148, 'loss': 0.8064928, 'global_step': 99001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6374, 'loss': 1.2913167, 'global_step': 99001}\n",
      "(0.73148, 0.6374)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75598, 'loss': 0.71380997, 'global_step': 100001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6529, 'loss': 1.1810066, 'global_step': 100001}\n",
      "(0.75598, 0.6529)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.66484, 'loss': 0.95622617, 'global_step': 101001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6138, 'loss': 1.1818494, 'global_step': 101001}\n",
      "(0.66484, 0.6138)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.74978, 'loss': 0.7491102, 'global_step': 102001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6488, 'loss': 1.4252856, 'global_step': 102001}\n",
      "(0.74978, 0.6488)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75928, 'loss': 0.71270293, 'global_step': 103001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6642, 'loss': 1.1594943, 'global_step': 103001}\n",
      "(0.75928, 0.6642)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76108, 'loss': 0.6933735, 'global_step': 104001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6498, 'loss': 1.2764015, 'global_step': 104001}\n",
      "(0.76108, 0.6498)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77096, 'loss': 0.65057, 'global_step': 105001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6594, 'loss': 1.140803, 'global_step': 105001}\n",
      "(0.77096, 0.6594)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75258, 'loss': 0.7066101, 'global_step': 106001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6495, 'loss': 1.1272835, 'global_step': 106001}\n",
      "(0.75258, 0.6495)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76904, 'loss': 0.7141789, 'global_step': 107001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6525, 'loss': 1.2511997, 'global_step': 107001}\n",
      "(0.76904, 0.6525)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7592, 'loss': 0.7299819, 'global_step': 108001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6458, 'loss': 1.3443642, 'global_step': 108001}\n",
      "(0.7592, 0.6458)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77436, 'loss': 0.67029214, 'global_step': 109001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6556, 'loss': 1.2516639, 'global_step': 109001}\n",
      "(0.77436, 0.6556)\n",
      "Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77278, 'loss': 0.6894009, 'global_step': 110001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6525, 'loss': 1.2114736, 'global_step': 110001}\n",
      "(0.77278, 0.6525)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76498, 'loss': 0.71335316, 'global_step': 111001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6563, 'loss': 1.4325769, 'global_step': 111001}\n",
      "(0.76498, 0.6563)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77522, 'loss': 0.7132534, 'global_step': 112001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6577, 'loss': 1.3224963, 'global_step': 112001}\n",
      "(0.77522, 0.6577)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.72958, 'loss': 0.7611573, 'global_step': 113001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6334, 'loss': 1.1858827, 'global_step': 113001}\n",
      "(0.72958, 0.6334)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77982, 'loss': 0.63488376, 'global_step': 114001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6605, 'loss': 1.1464925, 'global_step': 114001}\n",
      "(0.77982, 0.6605)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75778, 'loss': 0.708762, 'global_step': 115001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6446, 'loss': 1.23337, 'global_step': 115001}\n",
      "(0.75778, 0.6446)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76946, 'loss': 0.70256543, 'global_step': 116001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6546, 'loss': 1.3076288, 'global_step': 116001}\n",
      "(0.76946, 0.6546)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76784, 'loss': 0.6804728, 'global_step': 117001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6569, 'loss': 1.3493997, 'global_step': 117001}\n",
      "(0.76784, 0.6569)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78086, 'loss': 0.66384465, 'global_step': 118001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6589, 'loss': 1.1767132, 'global_step': 118001}\n",
      "(0.78086, 0.6589)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77624, 'loss': 0.6528061, 'global_step': 119001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6591, 'loss': 1.2121277, 'global_step': 119001}\n",
      "(0.77624, 0.6591)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77132, 'loss': 0.714776, 'global_step': 120001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6529, 'loss': 1.472501, 'global_step': 120001}\n",
      "(0.77132, 0.6529)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77322, 'loss': 0.7041114, 'global_step': 121001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6528, 'loss': 1.309724, 'global_step': 121001}\n",
      "(0.77322, 0.6528)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77836, 'loss': 0.6486967, 'global_step': 122001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6633, 'loss': 1.3513608, 'global_step': 122001}\n",
      "(0.77836, 0.6633)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76904, 'loss': 0.68592083, 'global_step': 123001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6531, 'loss': 1.2055768, 'global_step': 123001}\n",
      "(0.76904, 0.6531)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7823, 'loss': 0.6615097, 'global_step': 124001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6612, 'loss': 1.1712905, 'global_step': 124001}\n",
      "(0.7823, 0.6612)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78196, 'loss': 0.6425001, 'global_step': 125001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6566, 'loss': 1.2005353, 'global_step': 125001}\n",
      "(0.78196, 0.6566)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78202, 'loss': 0.6327483, 'global_step': 126001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6588, 'loss': 1.1638982, 'global_step': 126001}\n",
      "(0.78202, 0.6588)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78326, 'loss': 0.6300987, 'global_step': 127001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6568, 'loss': 1.1940981, 'global_step': 127001}\n",
      "(0.78326, 0.6568)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77726, 'loss': 0.72709644, 'global_step': 128001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6526, 'loss': 1.2147748, 'global_step': 128001}\n",
      "(0.77726, 0.6526)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78488, 'loss': 0.62243295, 'global_step': 129001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6533, 'loss': 1.2434713, 'global_step': 129001}\n",
      "(0.78488, 0.6533)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78088, 'loss': 0.6462331, 'global_step': 130001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6551, 'loss': 1.2081932, 'global_step': 130001}\n",
      "(0.78088, 0.6551)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.64904, 'loss': 1.1374276, 'global_step': 131001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5867, 'loss': 1.4377037, 'global_step': 131001}\n",
      "(0.64904, 0.5867)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78048, 'loss': 0.648289, 'global_step': 132001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.66, 'loss': 1.3059168, 'global_step': 132001}\n",
      "(0.78048, 0.66)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7659, 'loss': 0.690123, 'global_step': 133001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.659, 'loss': 1.2021477, 'global_step': 133001}\n",
      "(0.7659, 0.659)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7854, 'loss': 0.61395746, 'global_step': 134001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6579, 'loss': 1.268559, 'global_step': 134001}\n",
      "(0.7854, 0.6579)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78856, 'loss': 0.6224937, 'global_step': 135001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.668, 'loss': 1.2770796, 'global_step': 135001}\n",
      "(0.78856, 0.668)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76306, 'loss': 0.78861105, 'global_step': 136001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6502, 'loss': 1.2794863, 'global_step': 136001}\n",
      "(0.76306, 0.6502)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78124, 'loss': 0.64644116, 'global_step': 137001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6539, 'loss': 1.1919515, 'global_step': 137001}\n",
      "(0.78124, 0.6539)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77926, 'loss': 0.7045805, 'global_step': 138001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6456, 'loss': 1.448665, 'global_step': 138001}\n",
      "(0.77926, 0.6456)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77332, 'loss': 0.67973286, 'global_step': 139001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.644, 'loss': 1.4114099, 'global_step': 139001}\n",
      "(0.77332, 0.644)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78432, 'loss': 0.6539751, 'global_step': 140001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6625, 'loss': 1.3020796, 'global_step': 140001}\n",
      "(0.78432, 0.6625)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78098, 'loss': 0.6575207, 'global_step': 141001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6525, 'loss': 1.2372534, 'global_step': 141001}\n",
      "(0.78098, 0.6525)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78818, 'loss': 0.6138545, 'global_step': 142001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6605, 'loss': 1.3467191, 'global_step': 142001}\n",
      "(0.78818, 0.6605)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.79264, 'loss': 0.60857457, 'global_step': 143001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6536, 'loss': 1.3198377, 'global_step': 143001}\n",
      "(0.79264, 0.6536)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76644, 'loss': 0.689773, 'global_step': 144001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6432, 'loss': 1.3795041, 'global_step': 144001}\n",
      "(0.76644, 0.6432)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78414, 'loss': 0.64900196, 'global_step': 145001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6561, 'loss': 1.3628504, 'global_step': 145001}\n",
      "(0.78414, 0.6561)\n",
      "Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78604, 'loss': 0.62935525, 'global_step': 146001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6605, 'loss': 1.3320278, 'global_step': 146001}\n",
      "(0.78604, 0.6605)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78608, 'loss': 0.6233431, 'global_step': 147001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6558, 'loss': 1.4000837, 'global_step': 147001}\n",
      "(0.78608, 0.6558)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78148, 'loss': 0.6803876, 'global_step': 148001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6525, 'loss': 1.3163692, 'global_step': 148001}\n",
      "(0.78148, 0.6525)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77104, 'loss': 0.66343504, 'global_step': 149001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6553, 'loss': 1.1609064, 'global_step': 149001}\n",
      "(0.77104, 0.6553)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77874, 'loss': 0.66447467, 'global_step': 150001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6549, 'loss': 1.2058935, 'global_step': 150001}\n",
      "(0.77874, 0.6549)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78, 'loss': 0.6958936, 'global_step': 151001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6568, 'loss': 1.388167, 'global_step': 151001}\n",
      "(0.78, 0.6568)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.49376, 'loss': 1.4518802, 'global_step': 152001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.4817, 'loss': 1.5125731, 'global_step': 152001}\n",
      "(0.49376, 0.4817)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.56638, 'loss': 1.2671798, 'global_step': 153001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5479, 'loss': 1.4534681, 'global_step': 153001}\n",
      "(0.56638, 0.5479)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.62342, 'loss': 1.0670383, 'global_step': 154001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.5836, 'loss': 1.2242734, 'global_step': 154001}\n",
      "(0.62342, 0.5836)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.66774, 'loss': 0.9472667, 'global_step': 155001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6113, 'loss': 1.1775811, 'global_step': 155001}\n",
      "(0.66774, 0.6113)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7271, 'loss': 0.78541404, 'global_step': 156001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6372, 'loss': 1.202727, 'global_step': 156001}\n",
      "(0.7271, 0.6372)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.71944, 'loss': 0.8434005, 'global_step': 157001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6391, 'loss': 1.2442166, 'global_step': 157001}\n",
      "(0.71944, 0.6391)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.75148, 'loss': 0.74091685, 'global_step': 158001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6497, 'loss': 1.2636758, 'global_step': 158001}\n",
      "(0.75148, 0.6497)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76774, 'loss': 0.6693449, 'global_step': 159001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.653, 'loss': 1.1802261, 'global_step': 159001}\n",
      "(0.76774, 0.653)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76528, 'loss': 0.68260187, 'global_step': 160001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6487, 'loss': 1.2517794, 'global_step': 160001}\n",
      "(0.76528, 0.6487)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76506, 'loss': 0.7190131, 'global_step': 161001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6558, 'loss': 1.2936903, 'global_step': 161001}\n",
      "(0.76506, 0.6558)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7832, 'loss': 0.66135055, 'global_step': 162001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6579, 'loss': 1.2024739, 'global_step': 162001}\n",
      "(0.7832, 0.6579)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7829, 'loss': 0.6715266, 'global_step': 163001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6608, 'loss': 1.30341, 'global_step': 163001}\n",
      "(0.7829, 0.6608)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77824, 'loss': 0.6572696, 'global_step': 164001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6588, 'loss': 1.1580895, 'global_step': 164001}\n",
      "(0.77824, 0.6588)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78362, 'loss': 0.6650128, 'global_step': 165001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6526, 'loss': 1.3094684, 'global_step': 165001}\n",
      "(0.78362, 0.6526)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78418, 'loss': 0.65861905, 'global_step': 166001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6561, 'loss': 1.3745943, 'global_step': 166001}\n",
      "(0.78418, 0.6561)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78416, 'loss': 0.616473, 'global_step': 167001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6561, 'loss': 1.1949365, 'global_step': 167001}\n",
      "(0.78416, 0.6561)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78808, 'loss': 0.63373494, 'global_step': 168001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6591, 'loss': 1.2580478, 'global_step': 168001}\n",
      "(0.78808, 0.6591)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78494, 'loss': 0.609442, 'global_step': 169001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6557, 'loss': 1.2354618, 'global_step': 169001}\n",
      "(0.78494, 0.6557)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.79834, 'loss': 0.5901997, 'global_step': 170001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6655, 'loss': 1.2462288, 'global_step': 170001}\n",
      "(0.79834, 0.6655)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78158, 'loss': 0.6537508, 'global_step': 171001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6446, 'loss': 1.3896264, 'global_step': 171001}\n",
      "(0.78158, 0.6446)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.79166, 'loss': 0.63715667, 'global_step': 172001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6529, 'loss': 1.3355861, 'global_step': 172001}\n",
      "(0.79166, 0.6529)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78756, 'loss': 0.6478661, 'global_step': 173001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6565, 'loss': 1.3245734, 'global_step': 173001}\n",
      "(0.78756, 0.6565)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.80142, 'loss': 0.57349676, 'global_step': 174001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6573, 'loss': 1.4453388, 'global_step': 174001}\n",
      "(0.80142, 0.6573)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.76706, 'loss': 0.6887613, 'global_step': 175001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6475, 'loss': 1.2655988, 'global_step': 175001}\n",
      "(0.76706, 0.6475)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.78848, 'loss': 0.64671975, 'global_step': 176001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6599, 'loss': 1.2797848, 'global_step': 176001}\n",
      "(0.78848, 0.6599)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.79452, 'loss': 0.6250585, 'global_step': 177001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6544, 'loss': 1.3552136, 'global_step': 177001}\n",
      "(0.79452, 0.6544)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.77544, 'loss': 0.67486453, 'global_step': 178001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6559, 'loss': 1.2222202, 'global_step': 178001}\n",
      "(0.77544, 0.6559)\n",
      "Training\n",
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.79508, 'loss': 0.63411397, 'global_step': 179001}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6573, 'loss': 1.4691885, 'global_step': 179001}\n",
      "(0.79508, 0.6573)\n",
      "Training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e43465ac597f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       hooks=None)\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#print(curr_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "cifar_classifier = tf.estimator.Estimator(\n",
    "  model_fn=cnn_model_fn, model_dir=\"./CIFAR_10_fs\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "print(\"started\\n\")\n",
    "# Train the model\n",
    "i = 0 \n",
    "while 1:\n",
    "    if i:\n",
    "        curr_result = current_loss(1)\n",
    "        print(curr_result)\n",
    "        if curr_result[1] > 0.82:\n",
    "            break\n",
    "# Train the model\n",
    "    print(\"Training\")\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=256,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "\n",
    "    cifar_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=1000,\n",
    "      hooks=None)\n",
    "    i=1\n",
    "    #print(curr_result)\n",
    "print (\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%% Train accuracy %%%%%%%%%%%%\n",
      " {'accuracy': 0.7953, 'loss': 0.610918, 'global_step': 179002}\n",
      "######### Test accuracy #############\n",
      " {'accuracy': 0.6559, 'loss': 1.2265856, 'global_step': 179002}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7953, 0.6559)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_loss(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

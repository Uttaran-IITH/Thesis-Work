{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:01.137042Z",
     "start_time": "2018-11-05T08:48:59.269514Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttaran/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import ipynb.fs.full.Structural_Perturbations as SP\n",
    "import ipynb.fs.full.MultiTest as MT\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:01.693590Z",
     "start_time": "2018-11-05T08:49:01.153188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "0.76470596\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADZVJREFUeJzt3X+IHPUZx/HPY2xRrvkj/kh6XGyuFVFDwFSOQ0gtBrWoqLF/NEQEU1p6glFaUKgo2kApltpWC0rgSs9GqfkBJk38ga2EYqKEYBSJxmgMNTZXw52akh+IBOPTP26uXOPNd/Z2Z3b28rxfEHZ3np2ZhyWfm9mdH19zdwGI57S6GwBQD8IPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo09u5MjPjdEKgYu5ujbyvpS2/mV1jZu+a2T4zu6eVZQFoL2v23H4zmyFpr6SrJQ1LelXSze7+dmIetvxAxdqx5e+XtM/d/+nuxyWtlbSkheUBaKNWwt8j6cCE18PZtP9jZgNmttPMdrawLgAla+UHv8l2Lb60W+/ug5IGJXb7gU7SypZ/WNJ5E17PlfRha+0AaJdWwv+qpAvM7Jtm9lVJyyRtLqctAFVrerff3T83szsk/U3SDElD7r67tM4AVKrpQ31NrYzv/EDl2nKSD4Dpi/ADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgmh6iW5LMbL+ko5JOSPrc3fvKaApA9VoKf2axu39cwnIAtBG7/UBQrYbfJf3dzF4zs4EyGgLQHq3u9i9y9w/NbLakF83sHXffOvEN2R8F/jAAHcbcvZwFma2UdMzdf5t4TzkrA5DL3a2R9zW9229mXWY2c/y5pO9JeqvZ5QFor1Z2++dI2mhm48t5yt1fKKUrAJUrbbe/oZWx2w9UrvLdfgDTG+EHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoMu7ei5rNmTMntzZv3rzkvMePH0/W33jjjaZ6aoe+vvSd4k87LX/bdsMNNyTnvfjii5vqadyuXbuS9ccffzy3duDAgZbW3Si2/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFLfungYWLVqUrC9btiy3tmLFiuS827dvb2ndRWbPnp1bu/TSS5PzFvV+3XXXJevZmBId6aWXXsqtLV68uKVlc+tuAEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBU4fX8ZjYk6XpJo+6+IJt2lqR1knol7Ze01N3/U12b09vZZ5+drKeu7Zakq666KllPXf/d39+fnPeDDz5I1i+77LJk/e67707WU8fye3t7k/NW6ZVXXknWX3755WR97dq1La1/dHS0pfnL0MiW/8+Srjlp2j2Strj7BZK2ZK8BTCOF4Xf3rZIOnTR5iaTV2fPVkm4quS8AFWv2O/8cdz8oSdlj/jmcADpS5ffwM7MBSQNVrwfA1DS75R8xs25Jyh5zf71w90F373P39N0WAbRVs+HfLGl59ny5pE3ltAOgXQrDb2ZrJG2XdKGZDZvZjyX9WtLVZvaepKuz1wCmEa7nL0HR9dcrV65M1i+//PKW1n/s2LHc2gsvvJCct+g4/qxZs5L1rq6uZL0VRec/HD58OFl/+OGHc2uffPJJct5PP/00We9kXM8PIInwA0ERfiAowg8ERfiBoAg/EBSH+hp05pln5ta2bduWnLfoFtVFBgcHk/Wenp7c2pVXXpmc96GHHmqqp3EbNmxI1vft29f0sosOt7Xz/+50wqE+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBU5bfxOlWkjikfP3680nWvW7cuWd+6dWtu7cSJE2W3g1MEW34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrr+Utw7bXXJuuPPfZYst7qUNX33Xdfbm3TpvR4KiMjI8l60S2u0Xm4nh9AEuEHgiL8QFCEHwiK8ANBEX4gKMIPBFV4nN/MhiRdL2nU3Rdk01ZK+omkj7K33evuzxeu7BQ9zl+kaJjrRx99NFm/8cYbk/VWhsnevXt3sv7+++8n60XDaG/cuHHKPaE1ZR7n/7OkayaZ/rC7L8z+FQYfQGcpDL+7b5V0qA29AGijVr7z32Fmu8xsyMzS+7UAOk6z4V8l6XxJCyUdlPS7vDea2YCZ7TSznU2uC0AFmgq/u4+4+wl3/0LSHyX1J9476O597t7XbJMAytdU+M2se8LL70t6q5x2ALRL4a27zWyNpCsknWNmw5J+IekKM1soySXtl3RbhT0CqADX808DCxcuTNbvuuuu3NqyZcuS886YMaOpnsYdPXo0WU8d57/zzjtbWjYmx/X8AJIIPxAU4QeCIvxAUIQfCIrwA0FxqO8UN3/+/GT9gQceSNaXLl2arJuljyql/n8VHYZcv359so7JcagPQBLhB4Ii/EBQhB8IivADQRF+ICjCDwTFcf7gii7pveiii5L1+++/P1lPnSfw2WefJeedN29esv7RRx8l61FxnB9AEuEHgiL8QFCEHwiK8ANBEX4gKMIPBMVxfrRk8eLFyfqWLVuaXnZ3d3eyPjIy0vSyT2Uc5weQRPiBoAg/EBThB4Ii/EBQhB8IivADQZ1e9AYzO0/SE5K+LukLSYPu/gczO0vSOkm9kvZLWuru/6mu1XrNnTs3tzY8PNzGTtrrwgsvTNaHhoaaXvaOHTuSdYborlYjW/7PJd3l7hdLukzSCjObL+keSVvc/QJJW7LXAKaJwvC7+0F3fz17flTSHkk9kpZIWp29bbWkm6pqEkD5pvSd38x6JX1b0g5Jc9z9oDT2B0LS7LKbA1Cdwu/848zsa5KelvQzdz9SNEbbhPkGJA001x6AqjS05Tezr2gs+H9x9w3Z5BEz687q3ZJGJ5vX3Qfdvc/d+8poGEA5CsNvY5v4P0na4+6/n1DaLGl59ny5pE3ltwegKoWX9JrZdyRtk/Smxg71SdK9Gvvev17SNyT9S9IP3P1QwbKm7SW9Bw4cyK0988wzyXkfeeSRZH3v3r1N9TTu3HPPza319PQk5+3q6krWn3zyyWS9t7c3WT9y5Ehu7ZZbbknO+9xzzyXrmFyjl/QWfud395cl5S3syqk0BaBzcIYfEBThB4Ii/EBQhB8IivADQRF+IChu3d2gSy65JLe2atWq5Lzz589P1tesWZOsr1+/Pll/8MEHc2v9/f3JeVt1+PDhZP3WW2/NrRWdH4HmcOtuAEmEHwiK8ANBEX4gKMIPBEX4gaAIPxAUx/lLcMYZZyTrCxYsqHT9t99+e25t5syZLS37+eefT9a3b9+erL/zzjstrR9Tx3F+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxAUx/mBUwzH+QEkEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIXhN7PzzOwfZrbHzHab2U+z6SvN7N9m9kb277rq2wVQlsKTfMysW1K3u79uZjMlvSbpJklLJR1z9982vDJO8gEq1+hJPqc3sKCDkg5mz4+a2R5JPa21B6BuU/rOb2a9kr4taUc26Q4z22VmQ2Y2K2eeATPbaWY7W+oUQKkaPrffzL4m6SVJv3L3DWY2R9LHklzSLzX21eBHBctgtx+oWKO7/Q2F38y+IulZSX9z999PUu+V9Ky7J+9USfiB6pV2YY+ZmaQ/SdozMfjZD4Hjvi/prak2CaA+jfza/x1J2yS9KemLbPK9km6WtFBju/37Jd2W/TiYWhZbfqBipe72l4XwA9Xjen4ASYQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCm/gWbKPJX0w4fU52bRO1Km9dWpfEr01q8ze5jX6xrZez/+llZvtdPe+2hpI6NTeOrUvid6aVVdv7PYDQRF+IKi6wz9Y8/pTOrW3Tu1Lordm1dJbrd/5AdSn7i0/gJrUEn4zu8bM3jWzfWZ2Tx095DGz/Wb2ZjbycK1DjGXDoI2a2VsTpp1lZi+a2XvZ46TDpNXUW0eM3JwYWbrWz67TRrxu+26/mc2QtFfS1ZKGJb0q6WZ3f7utjeQws/2S+ty99mPCZvZdScckPTE+GpKZ/UbSIXf/dfaHc5a7/7xDelupKY7cXFFveSNL/1A1fnZljnhdhjq2/P2S9rn7P939uKS1kpbU0EfHc/etkg6dNHmJpNXZ89Ua+8/Tdjm9dQR3P+jur2fPj0oaH1m61s8u0Vct6gh/j6QDE14Pq7OG/HZJfzez18xsoO5mJjFnfGSk7HF2zf2crHDk5nY6aWTpjvnsmhnxumx1hH+y0UQ66ZDDIne/VNK1klZku7dozCpJ52tsGLeDkn5XZzPZyNJPS/qZux+ps5eJJumrls+tjvAPSzpvwuu5kj6soY9JufuH2eOopI0a+5rSSUbGB0nNHkdr7ud/3H3E3U+4+xeS/qgaP7tsZOmnJf3F3Tdkk2v/7Cbrq67PrY7wvyrpAjP7ppl9VdIySZtr6ONLzKwr+yFGZtYl6XvqvNGHN0tanj1fLmlTjb38n04ZuTlvZGnV/Nl12ojXtZzkkx3KeETSDElD7v6rtjcxCTP7lsa29tLYFY9P1dmbma2RdIXGrvoakfQLSX+VtF7SNyT9S9IP3L3tP7zl9HaFpjhyc0W95Y0svUM1fnZljnhdSj+c4QfExBl+QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeC+i+fxjiB10xarwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data,train_labels,eval_data,eval_labels = SP.load(data='mnist')\n",
    "SP.Display(eval_data,433)\n",
    "print(eval_data[1000][433])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T05:20:37.126742Z",
     "start_time": "2018-09-18T05:20:36.910470Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "eval_data = SP.Scaling(eval_data,.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T10:05:22.875991Z",
     "start_time": "2018-09-17T10:05:22.731540Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "eval_data = Exposure(eval_data,+60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T16:19:05.540663Z",
     "start_time": "2018-09-28T16:19:05.331365Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "eval_data = SP.Rotation(eval_data,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T11:44:41.335928Z",
     "start_time": "2018-09-14T11:44:41.129965Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "eval_data = Translation(eval_data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T06:20:35.756830Z",
     "start_time": "2018-10-05T06:20:35.362024Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_data = SP.Exposure(train_data,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:03.839396Z",
     "start_time": "2018-11-05T08:49:03.664984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SP.Display(train_data,33337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:13.484503Z",
     "start_time": "2018-11-05T08:49:04.256949Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.empty([55000,784,6])\n",
    "for i in range(0, 6):\n",
    "    temp[:,:,i] = np.copy(train_data)\n",
    "temp[:,:,0] = SP.Exposure(temp[:,:,0],60)\n",
    "temp[:,:,1] = SP.Exposure(temp[:,:,1],-60)\n",
    "temp[:,:,2] = SP.Rotation(temp[:,:,2],-45)\n",
    "temp[:,:,3] = SP.Rotation(temp[:,:,3],45)\n",
    "temp[:,:,4] = SP.Scaling(temp[:,:,4],1.4)\n",
    "temp[:,:,5] = SP.Scaling(temp[:,:,5],0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:14.771511Z",
     "start_time": "2018-11-05T08:49:14.767756Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:15.461081Z",
     "start_time": "2018-11-05T08:49:15.264082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SP.Display(train_labels[:,:,5],33337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:16.066739Z",
     "start_time": "2018-11-05T08:49:16.063218Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_labels = train_labels.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:17.058985Z",
     "start_time": "2018-11-05T08:49:16.866734Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    print(\"0\")\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "    exp_pos_labels = tf.reshape(labels[:,:,0],[-1,28,28,1])\n",
    "    exp_neg_labels = tf.reshape(labels[:,:,1],[-1,28,28,1])\n",
    "    rot_clk_labels = tf.reshape(labels[:,:,2],[-1,28,28,1])\n",
    "    rot_aclk_labels = tf.reshape(labels[:,:,3],[-1,28,28,1])\n",
    "    scale_pos_labels = tf.reshape(labels[:,:,4],[-1,28,28,1])\n",
    "    scale_neg_labels = tf.reshape(labels[:,:,5],[-1,28,28,1])\n",
    "    print(\"1\")\n",
    "#     input()\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=4,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool1 = tf.contrib.layers.max_pool2d(inputs=conv1, kernel_size=2)\n",
    "\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=8,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool2 = tf.contrib.layers.max_pool2d(inputs=conv2, kernel_size=2)\n",
    "\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=16,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool3 = tf.contrib.layers.max_pool2d(inputs=conv3, kernel_size=2)\n",
    "\n",
    "    #     print(pool3.shape)\n",
    "    conv4 = tf.layers.conv2d_transpose(\n",
    "        inputs=pool3,\n",
    "        filters=16,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    exp_pos_conv5 = tf.layers.conv2d_transpose(\n",
    "        inputs=conv4,\n",
    "        filters=8,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    exp_pos_conv6 = tf.layers.conv2d_transpose(\n",
    "        inputs=exp_pos_conv5,\n",
    "        filters=4,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    #     print(conv6.shape)\n",
    "\n",
    "    exp_pos_conv7 = tf.layers.conv2d_transpose(\n",
    "        inputs=exp_pos_conv6,\n",
    "        filters=1,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=None)\n",
    "\n",
    "    exp_neg_conv5 = tf.layers.conv2d_transpose(\n",
    "        inputs=conv4,\n",
    "        filters=8,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    exp_neg_conv6 = tf.layers.conv2d_transpose(\n",
    "        inputs=exp_neg_conv5,\n",
    "        filters=4,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    #     print(conv6.shape)\n",
    "\n",
    "    exp_neg_conv7 = tf.layers.conv2d_transpose(\n",
    "        inputs=exp_neg_conv6,\n",
    "        filters=1,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=None)\n",
    "\n",
    "    rot_clk_conv5 = tf.layers.conv2d_transpose(\n",
    "        inputs=conv4,\n",
    "        filters=8,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    rot_clk_conv6 = tf.layers.conv2d_transpose(\n",
    "        inputs=rot_clk_conv5,\n",
    "        filters=4,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    #     print(conv6.shape)\n",
    "\n",
    "    rot_clk_conv7 = tf.layers.conv2d_transpose(\n",
    "        inputs=rot_clk_conv6,\n",
    "        filters=1,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=None)\n",
    "\n",
    "    rot_aclk_conv5 = tf.layers.conv2d_transpose(\n",
    "        inputs=conv4,\n",
    "        filters=8,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    rot_aclk_conv6 = tf.layers.conv2d_transpose(\n",
    "        inputs=rot_aclk_conv5,\n",
    "        filters=4,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    #     print(conv6.shape)\n",
    "\n",
    "    rot_aclk_conv7 = tf.layers.conv2d_transpose(\n",
    "        inputs=rot_clk_conv7,\n",
    "        filters=1,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=None)\n",
    "\n",
    "    scale_pos_conv5 = tf.layers.conv2d_transpose(\n",
    "        inputs=conv4,\n",
    "        filters=8,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    scale_pos_conv6 = tf.layers.conv2d_transpose(\n",
    "        inputs=scale_pos_conv5,\n",
    "        filters=4,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    #     print(conv6.shape)\n",
    "\n",
    "    scale_pos_conv7 = tf.layers.conv2d_transpose(\n",
    "        inputs=scale_pos_conv6,\n",
    "        filters=1,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=None)\n",
    "\n",
    "    scale_neg_conv5 = tf.layers.conv2d_transpose(\n",
    "        inputs=conv4,\n",
    "        filters=8,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    scale_neg_conv6 = tf.layers.conv2d_transpose(\n",
    "        inputs=scale_neg_conv5,\n",
    "        filters=4,\n",
    "        strides=2,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    #     print(conv6.shape)\n",
    "\n",
    "    scale_neg_conv7 = tf.layers.conv2d_transpose(\n",
    "        inputs=scale_neg_conv6,\n",
    "        filters=1,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=None)\n",
    "\n",
    "    #     print(conv7.shape)\n",
    "\n",
    "    paddings = tf.constant([[\n",
    "        0,\n",
    "        0,\n",
    "    ], [2, 2], [2, 2], [0, 0]])\n",
    "\n",
    "    exp_pos_conv7 = tf.pad(exp_pos_conv7, paddings, \"CONSTANT\")\n",
    "    exp_neg_conv7 = tf.pad(exp_neg_conv7, paddings, \"CONSTANT\")\n",
    "    rot_clk_conv7 = tf.pad(rot_clk_conv7, paddings, \"CONSTANT\")\n",
    "    rot_aclk_conv7 = tf.pad(rot_aclk_conv7, paddings, \"CONSTANT\")\n",
    "    scale_pos_conv7 = tf.pad(scale_pos_conv7, paddings, \"CONSTANT\")\n",
    "    scale_neg_conv7 = tf.pad(scale_neg_conv7, paddings, \"CONSTANT\")\n",
    "    #     print(conv7.shape)\n",
    "    #     print(labels.shape)\n",
    "    print(\"2\")\n",
    "    predictions = {\n",
    "        \"logits\": [\n",
    "            exp_pos_conv7, exp_neg_conv7, rot_clk_conv7, rot_aclk_conv7,\n",
    "            scale_pos_conv7, scale_neg_conv7\n",
    "        ]\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        print(\"3\")\n",
    "        input()\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.mean_squared_error(\n",
    "        labels=exp_pos_labels,\n",
    "        predictions=exp_pos_conv7) + tf.losses.mean_squared_error(\n",
    "            labels=exp_neg_labels,\n",
    "            predictions=exp_neg_conv7) + tf.losses.mean_squared_error(\n",
    "                labels=rot_clk_labels,\n",
    "                predictions=rot_clk_conv7) + tf.losses.mean_squared_error(\n",
    "                    labels=rot_aclk_labels,\n",
    "                    predictions=rot_aclk_conv7) + tf.losses.mean_squared_error(\n",
    "                        labels=scale_pos_labels, predictions=scale_pos_conv7\n",
    "                    ) + tf.losses.mean_squared_error(\n",
    "                        labels=scale_neg_labels, predictions=scale_neg_conv7)\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"rmse\":\n",
    "        tf.metrics.root_mean_squared_error(\n",
    "            tf.cast(labels, tf.float64), tf.cast(conv7, tf.float64))\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:17.608564Z",
     "start_time": "2018-11-05T08:49:17.599708Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './models/mnist_denoisingautoencoderall_multiop', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2f70ac0a20>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "  model_fn=cnn_model_fn, model_dir=\"./models/mnist_denoisingautoencoderall_multiop\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:49:18.852151Z",
     "start_time": "2018-11-05T08:49:18.839635Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def current_loss(flag,data=train_data,labels=train_labels):\n",
    "    print(labels[flag].shape)\n",
    "    train_eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": data[flag].reshape(28,28)},\n",
    "      y=labels[flag],\n",
    "      shuffle=False)\n",
    "    eval_result1=mnist_classifier.predict(input_fn=train_eval_input_fn,yield_single_examples = False)\n",
    "    input()\n",
    "    print(\"Here\")\n",
    "    a = list(eval_result1)[0]['logits']\n",
    "    print(type(a))\n",
    "    input()\n",
    "    plt.subplot(231)\n",
    "    plt.imshow(data[flag].reshape(28,28),cmap='gray')\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(a.reshape(28,28),cmap='gray')\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(labels[flag].reshape(28,28),cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T09:34:44.287730Z",
     "start_time": "2018-10-24T09:34:44.278053Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def l0_loss(labels,predictions):\n",
    "    \n",
    "    #last dimension deleted\n",
    "    labels = tf.reshape(labels,[-1,28,28])\n",
    "    predictions = tf.reshape(predictions,[-1,28,28])\n",
    "    \n",
    "    #counting number of different pixels\n",
    "    count = tf.Variable(0, dtype=tf.float32)\n",
    "    \n",
    "    #flattening layers for faster computation\n",
    "    labels = tf.contrib.layers.flatten(labels)\n",
    "    predictions = tf.contrib.layers.flatten(predictions)\n",
    "    #shape is 256x784\n",
    "    result = labels - predictions\n",
    "    \n",
    "    for i in range(0,labels.shape[0]):\n",
    "    #count = tf.to_float(tf.count_nonzero(result))\n",
    "        count+=tf.to_float(tf.count_nonzero(abs(labels[i]-predictions[i])))\n",
    "    print(count)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:33:40.987154Z",
     "start_time": "2018-11-04T16:33:40.956220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 6)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() got an unexpected keyword argument 'yield_single_examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-8185ddfdf790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-c6a5a1bdde06>\u001b[0m in \u001b[0;36mcurrent_loss\u001b[0;34m(flag, data, labels)\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       shuffle=False)\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0meval_result1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_eval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myield_single_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'yield_single_examples'"
     ]
    }
   ],
   "source": [
    "c = np.random.randint(0,55000)\n",
    "current_loss(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-05T08:53:54.441Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"started\\n\")\n",
    "# Train the model\n",
    "while 1:\n",
    "    \n",
    "# Train the model\n",
    "    print(\"Training\")\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=256,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "\n",
    "    mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=1000,\n",
    "      hooks=None,)\n",
    "#     c = np.random.randint(0,55000)\n",
    "#     current_loss(c)\n",
    "#     print(\"Step\")\n",
    "#     if curr_result[0] - curr_result[1] > 0.10 or curr_result[1] > 0.98:\n",
    "#        break\n",
    "#     print(curr_result)\n",
    "    \n",
    "print (\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T15:31:02.919381Z",
     "start_time": "2018-11-04T15:30:52.716Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "eval_data = SP.load('mnist')[2]\n",
    "eval_labels = np.copy(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:57:46.760921Z",
     "start_time": "2018-10-10T10:57:46.551051Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "eval_data = SP.Translation(eval_data,2)\n",
    "eval_data = SP.Exposure(eval_data,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:57:47.345411Z",
     "start_time": "2018-10-10T10:57:47.343060Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "eval_labels = eval_labels.reshape(-1,28,28)\n",
    "eval_data = eval_data.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T16:16:06.272171Z",
     "start_time": "2018-11-04T16:16:04.876485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-ae94d9edc33f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m919\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-1990351da424>\u001b[0m in \u001b[0;36mcurrent_loss\u001b[0;34m(flag, data, labels)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0meval_result1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_eval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_result1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_result1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path)\u001b[0m\n\u001b[1;32m    407\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m       features = self._get_features_from_input_fn(\n\u001b[0;32m--> 409\u001b[0;31m           input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[1;32m    410\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m    411\u001b[0m           features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_features_from_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUEUE_RUNNERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m       logging.warning('Input graph does not contain a QueueRunner. '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/numpy_io.py\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mordered_dict_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munique_target_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mordered_dict_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m       shape_dict_of_x = {k: ordered_dict_x[k].shape\n\u001b[1;32m    111\u001b[0m                          for k in ordered_dict_x.keys()}\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/numpy_io.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mordered_dict_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munique_target_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mordered_dict_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m       shape_dict_of_x = {k: ordered_dict_x[k].shape\n\u001b[1;32m    111\u001b[0m                          for k in ordered_dict_x.keys()}\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "current_loss(919,eval_data,eval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
